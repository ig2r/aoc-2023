{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "with open('sample.txt', 'r') as f:\n",
    "  lines = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "  (src, dests) = re.search(r'(.+):\\s?(.*)', line).groups()\n",
    "  return (src, re.split(r'\\s+', dests))\n",
    "\n",
    "rels = list(map(parse_line, lines))\n",
    "\n",
    "def get_edge_names(rels):\n",
    "  edges = set()\n",
    "  for (src, dests) in rels:\n",
    "    edges.add(src)\n",
    "    for dest in dests:\n",
    "      edges.add(dest)\n",
    "  return sorted(edges)\n",
    "\n",
    "\n",
    "# Build affinity matrix\n",
    "def get_affinity_matrix(rels):\n",
    "  edge_names = get_edge_names(rels)\n",
    "  A = np.zeros((len(edge_names), len(edge_names)), dtype=int)\n",
    "\n",
    "  for (src, dests) in rels:\n",
    "    i_src = edge_names.index(src)\n",
    "    for dest in dests:\n",
    "      i_dest = edge_names.index(dest)\n",
    "      A[i_src, i_dest] = 1\n",
    "      A[i_dest, i_src] = 1\n",
    "\n",
    "  return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll run Karger's algorithm to estimate a global min-cut.\n",
    "\n",
    "while True:\n",
    "  G = get_affinity_matrix(rels)\n",
    "  G = np.triu(G)\n",
    "\n",
    "  edges = list(np.transpose(np.nonzero(G)))\n",
    "\n",
    "  # We'll represent \"merged\" vertices by assigning them the same ID. Initially,\n",
    "  # no vertices have been merged, so each vertex has its own ID.\n",
    "  vertex_group_ids = np.arange(G.shape[0])\n",
    "\n",
    "  while len(np.unique(vertex_group_ids)) > 2:\n",
    "    #print(f'Running for {len(np.unique(vertex_group_ids))} vertices...')\n",
    "\n",
    "    idx = np.random.randint(len(edges))\n",
    "    i, j = edges.pop(idx)\n",
    "    #print(f'  i, j: {i}, {j}')\n",
    "\n",
    "    i_vertices = (vertex_group_ids == vertex_group_ids[i])\n",
    "    j_vertices = (vertex_group_ids == vertex_group_ids[j])\n",
    "\n",
    "    # Remove all edges between vertices in these groups\n",
    "    G[np.ix_(i_vertices, j_vertices)] = 0\n",
    "    G[np.ix_(j_vertices, i_vertices)] = 0\n",
    "\n",
    "    # Reassign all vertices in group \"j\" to the other group\n",
    "    vertex_group_ids[j_vertices] = vertex_group_ids[i]\n",
    "\n",
    "\n",
    "  min_cut_size = np.sum(np.triu(G))\n",
    "  group_counts = np.unique(vertex_group_ids, return_counts=True)[1]\n",
    "\n",
    "  print(f'min_cut_size: {min_cut_size}   group_counts: {group_counts}')\n",
    "\n",
    "  if min_cut_size == 3:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
