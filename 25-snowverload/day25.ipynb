{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "with open('sample.txt', 'r') as f:\n",
    "  lines = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "  (src, dests) = re.search(r'(.+):\\s?(.*)', line).groups()\n",
    "  return (src, re.split(r'\\s+', dests))\n",
    "\n",
    "rels = list(map(parse_line, lines))\n",
    "\n",
    "def get_edge_names(rels):\n",
    "  edges = set()\n",
    "  for (src, dests) in rels:\n",
    "    edges.add(src)\n",
    "    for dest in dests:\n",
    "      edges.add(dest)\n",
    "  return sorted(edges)\n",
    "\n",
    "# Build affinity matrix\n",
    "def get_affinity_matrix(rels):\n",
    "  edge_names = get_edge_names(rels)\n",
    "  A = np.zeros((len(edge_names), len(edge_names)), dtype=int)\n",
    "\n",
    "  for (src, dests) in rels:\n",
    "    i_src = edge_names.index(src)\n",
    "    for dest in dests:\n",
    "      i_dest = edge_names.index(dest)\n",
    "      A[i_src, i_dest] = 1\n",
    "      A[i_dest, i_src] = 1\n",
    "\n",
    "  return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll run Karger's algorithm on the graph to find a cut. Since we know the min-cut is of\n",
    "# size 3, we can simply repeat the procedure until we find a cut with that exact size.\n",
    "\n",
    "def contract(G, e):\n",
    "  i, j = e\n",
    "\n",
    "  # Merge row/col j into i-th row/col\n",
    "  G[i, :] += G[j, :]\n",
    "  G[:, i] += G[:, j]\n",
    "  G[i, i] = 0\n",
    "\n",
    "  # Drop j-th row/col from G\n",
    "  G = np.delete(G, j, axis=0)\n",
    "  G = np.delete(G, j, axis=1)\n",
    "\n",
    "  return G\n",
    "\n",
    "def random_edge(G):\n",
    "  edges = np.transpose(np.nonzero(G))\n",
    "  weights = G[edges[:, 0], edges[:, 1]]\n",
    "  idx = np.random.choice(edges.shape[0], p=(weights / np.sum(weights)))\n",
    "  return edges[idx]\n",
    "\n",
    "G_original = get_affinity_matrix(rels)\n",
    "\n",
    "while True:\n",
    "  G = G_original.copy()\n",
    "  vertex_group_counts = np.ones(G.shape[0], dtype=int)\n",
    "\n",
    "  while G.shape[0] > 2:\n",
    "    e = random_edge(G)\n",
    "    G = contract(G, e)\n",
    "\n",
    "    # Keep track of how many vertices have been merged at each row/col of the\n",
    "    # graph's affinity matrix; we need this to compute group sizes\n",
    "    i, j = e\n",
    "    vertex_group_counts[i] += vertex_group_counts[j]\n",
    "    vertex_group_counts = np.delete(vertex_group_counts, j)\n",
    "\n",
    "  min_cut = G[0, 1]\n",
    "  print(min_cut, vertex_group_counts, np.prod(vertex_group_counts))\n",
    "\n",
    "  if min_cut == 3:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
